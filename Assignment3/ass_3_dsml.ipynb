{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ass_3_dsml.ipynb","provenance":[],"authorship_tag":"ABX9TyP+3Q5s7r9zAaOcnLxeIiIA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"TMyi8Z5n7nUh","executionInfo":{"status":"ok","timestamp":1616334323796,"user_tz":-330,"elapsed":3109,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn as sk\n","import pandas as pd\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPClassifier"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgrqpqPx7qDI","executionInfo":{"status":"ok","timestamp":1616334327149,"user_tz":-330,"elapsed":1047,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"b27533cb-2f43-49eb-a6c5-8e6c0fbe912c"},"source":["!wget https://raw.githubusercontent.com/Dinesh-Adhithya-H/Applied-machine-learning/master/Train.csv"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-03-21 13:45:27--  https://raw.githubusercontent.com/Dinesh-Adhithya-H/Applied-machine-learning/master/Train.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6106 (6.0K) [text/plain]\n","Saving to: ‘Train.csv’\n","\n","Train.csv           100%[===================>]   5.96K  --.-KB/s    in 0s      \n","\n","2021-03-21 13:45:27 (71.2 MB/s) - ‘Train.csv’ saved [6106/6106]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ui3Rg3sk8YMu","executionInfo":{"status":"ok","timestamp":1616334329286,"user_tz":-330,"elapsed":798,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["data=pd.read_csv(\"/content/Train.csv\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLb-MKcBAXfQ","executionInfo":{"status":"ok","timestamp":1616334331331,"user_tz":-330,"elapsed":1071,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["from sklearn.utils import shuffle\n","data= shuffle(data)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"L9mIRuy88rl5","executionInfo":{"status":"ok","timestamp":1616334367801,"user_tz":-330,"elapsed":779,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"f95d0f19-1f48-44a5-94e5-a9f997541d97"},"source":["plt.hist(data[\"Category\"])\n","plt.show()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Ot0GvDp8_vym","executionInfo":{"status":"ok","timestamp":1616342989788,"user_tz":-330,"elapsed":1423,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["data.loc[(data['Category'] < 1.5)] = 0.0\n","data.loc[(data['Category'] > 1.5)] = 1.0"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"b55Z1xLa--IX","executionInfo":{"status":"ok","timestamp":1616342989789,"user_tz":-330,"elapsed":695,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["X=data.drop([\"Category\"],axis=1)\n","Y=data[\"Category\"]"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"OrUm382-jiiW","executionInfo":{"status":"ok","timestamp":1616343143590,"user_tz":-330,"elapsed":1013,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["test_data=m.transform(np.array(test_data))"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"id":"-MO9rZDJ_MlJ","executionInfo":{"status":"ok","timestamp":1616342992000,"user_tz":-330,"elapsed":803,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["m=StandardScaler().fit(np.array(X))\n","X=m.transform(X)\n","Y=np.array(Y)"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"xwlg1wPDETPc","executionInfo":{"status":"ok","timestamp":1616342993754,"user_tz":-330,"elapsed":805,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test=train_test_split(X,Y)"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnZUJqKqCb8B","executionInfo":{"status":"ok","timestamp":1616343376129,"user_tz":-330,"elapsed":1051,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"a8f7c429-5773-4e5c-eb91-327f9eb97fc2"},"source":["clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=300, alpha=0.0001,\n","                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n","clf.fit(x_train,y_train)"],"execution_count":116,"outputs":[{"output_type":"stream","text":["Iteration 1, loss = 0.92287268\n","Iteration 2, loss = 0.91753964\n","Iteration 3, loss = 0.90892452\n","Iteration 4, loss = 0.89772991\n","Iteration 5, loss = 0.88453976\n","Iteration 6, loss = 0.86983577\n","Iteration 7, loss = 0.85401273\n","Iteration 8, loss = 0.83739228\n","Iteration 9, loss = 0.82023500\n","Iteration 10, loss = 0.80275082\n","Iteration 11, loss = 0.78510786\n","Iteration 12, loss = 0.76743994\n","Iteration 13, loss = 0.74985276\n","Iteration 14, loss = 0.73242913\n","Iteration 15, loss = 0.71523327\n","Iteration 16, loss = 0.69831429\n","Iteration 17, loss = 0.68170914\n","Iteration 18, loss = 0.66544496\n","Iteration 19, loss = 0.64954098\n","Iteration 20, loss = 0.63401017\n","Iteration 21, loss = 0.61886045\n","Iteration 22, loss = 0.60409574\n","Iteration 23, loss = 0.58971683\n","Iteration 24, loss = 0.57572203\n","Iteration 25, loss = 0.56210770\n","Iteration 26, loss = 0.54886874\n","Iteration 27, loss = 0.53599888\n","Iteration 28, loss = 0.52349102\n","Iteration 29, loss = 0.51133742\n","Iteration 30, loss = 0.49952991\n","Iteration 31, loss = 0.48806000\n","Iteration 32, loss = 0.47691902\n","Iteration 33, loss = 0.46609822\n","Iteration 34, loss = 0.45558880\n","Iteration 35, loss = 0.44538201\n","Iteration 36, loss = 0.43546918\n","Iteration 37, loss = 0.42584173\n","Iteration 38, loss = 0.41649123\n","Iteration 39, loss = 0.40740942\n","Iteration 40, loss = 0.39858818\n","Iteration 41, loss = 0.39001960\n","Iteration 42, loss = 0.38169595\n","Iteration 43, loss = 0.37360969\n","Iteration 44, loss = 0.36575347\n","Iteration 45, loss = 0.35812016\n","Iteration 46, loss = 0.35070282\n","Iteration 47, loss = 0.34349469\n","Iteration 48, loss = 0.33648922\n","Iteration 49, loss = 0.32968006\n","Iteration 50, loss = 0.32306104\n","Iteration 51, loss = 0.31662617\n","Iteration 52, loss = 0.31039875\n","Iteration 53, loss = 0.30464428\n","Iteration 54, loss = 0.29903930\n","Iteration 55, loss = 0.29357876\n","Iteration 56, loss = 0.28825793\n","Iteration 57, loss = 0.28307232\n","Iteration 58, loss = 0.27801768\n","Iteration 59, loss = 0.27308997\n","Iteration 60, loss = 0.26828534\n","Iteration 61, loss = 0.26360009\n","Iteration 62, loss = 0.25903067\n","Iteration 63, loss = 0.25457368\n","Iteration 64, loss = 0.25022582\n","Iteration 65, loss = 0.24598393\n","Iteration 66, loss = 0.24184495\n","Iteration 67, loss = 0.23780593\n","Iteration 68, loss = 0.23386400\n","Iteration 69, loss = 0.23001641\n","Iteration 70, loss = 0.22626046\n","Iteration 71, loss = 0.22259356\n","Iteration 72, loss = 0.21901321\n","Iteration 73, loss = 0.21551696\n","Iteration 74, loss = 0.21210245\n","Iteration 75, loss = 0.20876739\n","Iteration 76, loss = 0.20550956\n","Iteration 77, loss = 0.20232681\n","Iteration 78, loss = 0.19921704\n","Iteration 79, loss = 0.19617823\n","Iteration 80, loss = 0.19320842\n","Iteration 81, loss = 0.19030571\n","Iteration 82, loss = 0.18746823\n","Iteration 83, loss = 0.18469421\n","Iteration 84, loss = 0.18198189\n","Iteration 85, loss = 0.17932961\n","Iteration 86, loss = 0.17673571\n","Iteration 87, loss = 0.17419862\n","Iteration 88, loss = 0.17171679\n","Iteration 89, loss = 0.16928874\n","Iteration 90, loss = 0.16691301\n","Iteration 91, loss = 0.16458820\n","Iteration 92, loss = 0.16231295\n","Iteration 93, loss = 0.16008594\n","Iteration 94, loss = 0.15790589\n","Iteration 95, loss = 0.15577154\n","Iteration 96, loss = 0.15368171\n","Iteration 97, loss = 0.15163522\n","Iteration 98, loss = 0.14963092\n","Iteration 99, loss = 0.14766773\n","Iteration 100, loss = 0.14574457\n","Iteration 101, loss = 0.14386041\n","Iteration 102, loss = 0.14201424\n","Iteration 103, loss = 0.14020508\n","Iteration 104, loss = 0.13843200\n","Iteration 105, loss = 0.13669406\n","Iteration 106, loss = 0.13499037\n","Iteration 107, loss = 0.13332008\n","Iteration 108, loss = 0.13168234\n","Iteration 109, loss = 0.13007633\n","Iteration 110, loss = 0.12850126\n","Iteration 111, loss = 0.12695637\n","Iteration 112, loss = 0.12544090\n","Iteration 113, loss = 0.12395413\n","Iteration 114, loss = 0.12249536\n","Iteration 115, loss = 0.12106391\n","Iteration 116, loss = 0.11965910\n","Iteration 117, loss = 0.11828030\n","Iteration 118, loss = 0.11692688\n","Iteration 119, loss = 0.11559822\n","Iteration 120, loss = 0.11429374\n","Iteration 121, loss = 0.11301287\n","Iteration 122, loss = 0.11175503\n","Iteration 123, loss = 0.11051970\n","Iteration 124, loss = 0.10930634\n","Iteration 125, loss = 0.10811444\n","Iteration 126, loss = 0.10694351\n","Iteration 127, loss = 0.10579305\n","Iteration 128, loss = 0.10466259\n","Iteration 129, loss = 0.10355168\n","Iteration 130, loss = 0.10245987\n","Iteration 131, loss = 0.10138673\n","Iteration 132, loss = 0.10033184\n","Iteration 133, loss = 0.09929478\n","Iteration 134, loss = 0.09827515\n","Iteration 135, loss = 0.09727258\n","Iteration 136, loss = 0.09628667\n","Iteration 137, loss = 0.09531706\n","Iteration 138, loss = 0.09436340\n","Iteration 139, loss = 0.09342533\n","Iteration 140, loss = 0.09250251\n","Iteration 141, loss = 0.09159463\n","Iteration 142, loss = 0.09070134\n","Iteration 143, loss = 0.08982234\n","Iteration 144, loss = 0.08895733\n","Iteration 145, loss = 0.08810601\n","Iteration 146, loss = 0.08726808\n","Iteration 147, loss = 0.08644327\n","Iteration 148, loss = 0.08563130\n","Iteration 149, loss = 0.08483190\n","Iteration 150, loss = 0.08404481\n","Iteration 151, loss = 0.08326978\n","Iteration 152, loss = 0.08250656\n","Iteration 153, loss = 0.08175491\n","Iteration 154, loss = 0.08101459\n","Iteration 155, loss = 0.08028537\n","Iteration 156, loss = 0.07956703\n","Iteration 157, loss = 0.07885934\n","Iteration 158, loss = 0.07816211\n","Iteration 159, loss = 0.07747511\n","Iteration 160, loss = 0.07679815\n","Iteration 161, loss = 0.07613102\n","Iteration 162, loss = 0.07547354\n","Iteration 163, loss = 0.07482552\n","Iteration 164, loss = 0.07418676\n","Iteration 165, loss = 0.07355710\n","Iteration 166, loss = 0.07293636\n","Iteration 167, loss = 0.07232436\n","Iteration 168, loss = 0.07172094\n","Iteration 169, loss = 0.07112594\n","Iteration 170, loss = 0.07053919\n","Iteration 171, loss = 0.06996055\n","Iteration 172, loss = 0.06938985\n","Iteration 173, loss = 0.06882696\n","Iteration 174, loss = 0.06827172\n","Iteration 175, loss = 0.06772400\n","Iteration 176, loss = 0.06718365\n","Iteration 177, loss = 0.06665054\n","Iteration 178, loss = 0.06612454\n","Iteration 179, loss = 0.06560552\n","Iteration 180, loss = 0.06509335\n","Iteration 181, loss = 0.06458792\n","Iteration 182, loss = 0.06408909\n","Iteration 183, loss = 0.06359675\n","Iteration 184, loss = 0.06311079\n","Iteration 185, loss = 0.06263109\n","Iteration 186, loss = 0.06215755\n","Iteration 187, loss = 0.06169005\n","Iteration 188, loss = 0.06122849\n","Iteration 189, loss = 0.06077276\n","Iteration 190, loss = 0.06032277\n","Iteration 191, loss = 0.05987842\n","Iteration 192, loss = 0.05943960\n","Iteration 193, loss = 0.05900623\n","Iteration 194, loss = 0.05857822\n","Iteration 195, loss = 0.05815546\n","Iteration 196, loss = 0.05773788\n","Iteration 197, loss = 0.05732538\n","Iteration 198, loss = 0.05691789\n","Iteration 199, loss = 0.05651531\n","Iteration 200, loss = 0.05611757\n","Iteration 201, loss = 0.05572458\n","Iteration 202, loss = 0.05533628\n","Iteration 203, loss = 0.05495257\n","Iteration 204, loss = 0.05457339\n","Iteration 205, loss = 0.05419867\n","Iteration 206, loss = 0.05382832\n","Iteration 207, loss = 0.05346229\n","Iteration 208, loss = 0.05310050\n","Iteration 209, loss = 0.05274288\n","Iteration 210, loss = 0.05238937\n","Iteration 211, loss = 0.05203990\n","Iteration 212, loss = 0.05169441\n","Iteration 213, loss = 0.05135283\n","Iteration 214, loss = 0.05101511\n","Iteration 215, loss = 0.05068119\n","Iteration 216, loss = 0.05035100\n","Iteration 217, loss = 0.05002449\n","Iteration 218, loss = 0.04970160\n","Iteration 219, loss = 0.04938228\n","Iteration 220, loss = 0.04906647\n","Iteration 221, loss = 0.04875412\n","Iteration 222, loss = 0.04844517\n","Iteration 223, loss = 0.04813958\n","Iteration 224, loss = 0.04783730\n","Iteration 225, loss = 0.04753826\n","Iteration 226, loss = 0.04724244\n","Iteration 227, loss = 0.04694977\n","Iteration 228, loss = 0.04666021\n","Iteration 229, loss = 0.04637373\n","Iteration 230, loss = 0.04609026\n","Iteration 231, loss = 0.04580977\n","Iteration 232, loss = 0.04553221\n","Iteration 233, loss = 0.04525754\n","Iteration 234, loss = 0.04498572\n","Iteration 235, loss = 0.04471672\n","Iteration 236, loss = 0.04445047\n","Iteration 237, loss = 0.04418696\n","Iteration 238, loss = 0.04392614\n","Iteration 239, loss = 0.04366797\n","Iteration 240, loss = 0.04341241\n","Iteration 241, loss = 0.04315943\n","Iteration 242, loss = 0.04290899\n","Iteration 243, loss = 0.04266106\n","Iteration 244, loss = 0.04241560\n","Iteration 245, loss = 0.04217257\n","Iteration 246, loss = 0.04193195\n","Iteration 247, loss = 0.04169370\n","Iteration 248, loss = 0.04145779\n","Iteration 249, loss = 0.04122418\n","Iteration 250, loss = 0.04099284\n","Iteration 251, loss = 0.04076375\n","Iteration 252, loss = 0.04053687\n","Iteration 253, loss = 0.04031218\n","Iteration 254, loss = 0.04008964\n","Iteration 255, loss = 0.03986922\n","Iteration 256, loss = 0.03965090\n","Iteration 257, loss = 0.03943465\n","Iteration 258, loss = 0.03922045\n","Iteration 259, loss = 0.03900825\n","Iteration 260, loss = 0.03879805\n","Iteration 261, loss = 0.03858981\n","Iteration 262, loss = 0.03838351\n","Iteration 263, loss = 0.03817911\n","Iteration 264, loss = 0.03797661\n","Iteration 265, loss = 0.03777597\n","Iteration 266, loss = 0.03757716\n","Iteration 267, loss = 0.03738018\n","Iteration 268, loss = 0.03718498\n","Iteration 269, loss = 0.03699155\n","Iteration 270, loss = 0.03679987\n","Iteration 271, loss = 0.03660992\n","Iteration 272, loss = 0.03642167\n","Iteration 273, loss = 0.03623510\n","Iteration 274, loss = 0.03605019\n","Iteration 275, loss = 0.03586692\n","Iteration 276, loss = 0.03568528\n","Iteration 277, loss = 0.03550523\n","Iteration 278, loss = 0.03532676\n","Iteration 279, loss = 0.03514985\n","Iteration 280, loss = 0.03497449\n","Iteration 281, loss = 0.03480065\n","Iteration 282, loss = 0.03462831\n","Iteration 283, loss = 0.03445746\n","Iteration 284, loss = 0.03428807\n","Iteration 285, loss = 0.03412014\n","Iteration 286, loss = 0.03395364\n","Iteration 287, loss = 0.03378856\n","Iteration 288, loss = 0.03362487\n","Iteration 289, loss = 0.03346257\n","Iteration 290, loss = 0.03330164\n","Iteration 291, loss = 0.03314205\n","Iteration 292, loss = 0.03298380\n","Iteration 293, loss = 0.03282687\n","Iteration 294, loss = 0.03267124\n","Iteration 295, loss = 0.03251689\n","Iteration 296, loss = 0.03236382\n","Iteration 297, loss = 0.03221201\n","Iteration 298, loss = 0.03206145\n","Iteration 299, loss = 0.03191211\n","Iteration 300, loss = 0.03176399\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n","              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n","              hidden_layer_sizes=10, learning_rate='constant',\n","              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n","              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n","              power_t=0.5, random_state=21, shuffle=True, solver='sgd',\n","              tol=1e-09, validation_fraction=0.1, verbose=10, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7p85ncJjUEa","executionInfo":{"status":"ok","timestamp":1616343377978,"user_tz":-330,"elapsed":828,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"ad4aade7-3b3b-4734-aaae-186352a6f897"},"source":["clf.predict(X)"],"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stBqNoXcCXmL","executionInfo":{"status":"ok","timestamp":1616343093810,"user_tz":-330,"elapsed":872,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"0c7f684b-90da-4261-fe85-89a51bebdfc9"},"source":["clf.predict(np.array(test_data))+1"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1])"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCobMCBeHL3V","executionInfo":{"status":"ok","timestamp":1616335693995,"user_tz":-330,"elapsed":751,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"d7dd564d-d437-4ec6-ad19-f9dbeab1fb34"},"source":["np.array(y_train)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n","       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n","       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n","       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n","       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n","       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 0])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sV1lGyFxHo3L","executionInfo":{"status":"ok","timestamp":1616336007434,"user_tz":-330,"elapsed":822,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"2925761e-0623-42aa-aa32-4d6b522a849a"},"source":["clf.predict(np.array(test_data))+1"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1,\n","       2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n","       2, 2, 1, 1])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"ZlAtjVnqH5ee"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2x9ix5RG2QL","executionInfo":{"status":"ok","timestamp":1616335644420,"user_tz":-330,"elapsed":826,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"2590db3e-67d9-482f-dd77-f811bc2b8d2a"},"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test,clf.predict(x_test))"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpESTfXxUPl7","executionInfo":{"status":"ok","timestamp":1616334381166,"user_tz":-330,"elapsed":755,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"6c170c60-f642-400f-81e1-0e0fe92a5f52"},"source":["m"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StandardScaler(copy=True, with_mean=True, with_std=True)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"dt-d-yfD8sGi","executionInfo":{"status":"ok","timestamp":1616322218363,"user_tz":-330,"elapsed":763,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["def create_model():\n","  model=tf.keras.models.Sequential([\n","  tf.keras.layers.Dense(10,input_shape=X[0].shape),\n","  #keras.layers.BatchNormalization(),\n","  tf.keras.layers.Dense(12,activation=\"relu\"),\n","  keras.layers.Dropout(0.1),\n","  #keras.layers.BatchNormalization(),\n","  tf.keras.layers.Dense(18,activation=\"relu\"),\n","  keras.layers.Dropout(0.1),\n","  #keras.layers.BatchNormalization(),\n","  tf.keras.layers.Dense(18,activation=\"relu\"),\n","  keras.layers.Dropout(0.1),\n","  keras.layers.BatchNormalization(),\n","  tf.keras.layers.Dense(18,activation=\"relu\"),\n","  keras.layers.Dropout(0.1),\n","  keras.layers.BatchNormalization(),\n","  tf.keras.layers.Dense(2,activation=\"relu\")])\n","  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n","  model.summary()\n","  return model"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1T9K1aSOwQa","executionInfo":{"status":"ok","timestamp":1616321166598,"user_tz":-330,"elapsed":956,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"f2b61740-b3a0-4b94-f79d-4329b8e8e2c8"},"source":["len(X)*0.75"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["206.25"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHYsbLSA-03k","executionInfo":{"status":"ok","timestamp":1616321078201,"user_tz":-330,"elapsed":22052,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"8bc5bb96-c09c-44e5-8c01-81e9677ab1f5"},"source":["from sklearn.model_selection import KFold\n","\n","n_split=10\n","for train_index,test_index in KFold(n_split).split(X):\n","  x_train,x_test=X[train_index],X[test_index]\n","  y_train,y_test=Y[train_index],Y[test_index]\n","  model=create_model()\n","  history=model.fit(x_train, y_train,verbose=1,batch_size=10)\n","  print('Model evaluation ',model.evaluate(x_test,y_test))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Model: \"sequential_24\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_96 (Dense)             (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_48 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_97 (Dense)             (None, 12)                132       \n","_________________________________________________________________\n","dropout_48 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_49 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_98 (Dense)             (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_49 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_50 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_99 (Dense)             (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_50 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_51 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_100 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_51 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_52 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_101 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 18ms/step - loss: 0.2180 - accuracy: 0.8641\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d1599200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 185ms/step - loss: 0.2159 - accuracy: 1.0000\n","Model evaluation  [0.2159285843372345, 1.0]\n","Model: \"sequential_25\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_102 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_53 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_103 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_52 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_54 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_104 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_53 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_55 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_105 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_54 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_56 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_106 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_55 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_57 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_107 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 17ms/step - loss: 0.4880 - accuracy: 0.8202\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d26c58c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 192ms/step - loss: 0.3259 - accuracy: 1.0000\n","Model evaluation  [0.3258908689022064, 1.0]\n","Model: \"sequential_26\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_108 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_58 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_109 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_56 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_59 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_110 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_57 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_60 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_111 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_58 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_61 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_112 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_59 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_62 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_113 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 16ms/step - loss: 0.3012 - accuracy: 0.8881\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5cbe91170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 187ms/step - loss: 0.0081 - accuracy: 1.0000\n","Model evaluation  [0.00808520894497633, 1.0]\n","Model: \"sequential_27\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_114 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_63 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_115 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_60 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_64 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_116 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_61 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_65 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_117 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_62 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_66 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_118 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_63 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_67 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_119 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 18ms/step - loss: 0.4481 - accuracy: 0.8651\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5de515320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 185ms/step - loss: 0.0304 - accuracy: 1.0000\n","Model evaluation  [0.030368110164999962, 1.0]\n","Model: \"sequential_28\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_120 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_68 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_121 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_64 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_69 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_122 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_65 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_70 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_123 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_66 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_71 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_124 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_67 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_72 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_125 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 17ms/step - loss: 0.5731 - accuracy: 0.8573\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5ca3cd440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 188ms/step - loss: 0.3370 - accuracy: 1.0000\n","Model evaluation  [0.3369565010070801, 1.0]\n","Model: \"sequential_29\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_126 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_73 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_127 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_68 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_74 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_128 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_69 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_75 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_129 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_70 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_76 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_130 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_71 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_77 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_131 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 18ms/step - loss: 0.8385 - accuracy: 0.8004\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d132bcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 186ms/step - loss: 0.0090 - accuracy: 1.0000\n","Model evaluation  [0.009002743288874626, 1.0]\n","Model: \"sequential_30\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_132 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_78 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_133 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_72 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_79 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_134 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_73 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_80 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_135 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_74 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_81 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_136 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_75 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_82 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_137 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 17ms/step - loss: 0.5276 - accuracy: 0.8052\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d028a440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 191ms/step - loss: 0.0524 - accuracy: 1.0000\n","Model evaluation  [0.05240786820650101, 1.0]\n","Model: \"sequential_31\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_138 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_83 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_139 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_76 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_84 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_140 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_77 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_85 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_141 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_78 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_86 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_142 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_79 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_87 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_143 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 17ms/step - loss: 0.6552 - accuracy: 0.8402\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d14050e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 186ms/step - loss: 0.3863 - accuracy: 0.5556\n","Model evaluation  [0.3863345980644226, 0.5555555820465088]\n","Model: \"sequential_32\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_144 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_88 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_145 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_80 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_89 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_146 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_81 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_90 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_147 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_82 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_91 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_148 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_83 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_92 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_149 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 17ms/step - loss: 0.5060 - accuracy: 0.8393\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d748b290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 190ms/step - loss: 2.0398e-06 - accuracy: 1.0000\n","Model evaluation  [2.0397992557263933e-06, 1.0]\n","Model: \"sequential_33\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_150 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","batch_normalization_93 (Batc (None, 10)                40        \n","_________________________________________________________________\n","dense_151 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_84 (Dropout)         (None, 12)                0         \n","_________________________________________________________________\n","batch_normalization_94 (Batc (None, 12)                48        \n","_________________________________________________________________\n","dense_152 (Dense)            (None, 1128)              14664     \n","_________________________________________________________________\n","dropout_85 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_95 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_153 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_86 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_96 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_154 (Dense)            (None, 1128)              1273512   \n","_________________________________________________________________\n","dropout_87 (Dropout)         (None, 1128)              0         \n","_________________________________________________________________\n","batch_normalization_97 (Batc (None, 1128)              4512      \n","_________________________________________________________________\n","dense_155 (Dense)            (None, 2)                 2258      \n","=================================================================\n","Total params: 2,577,772\n","Trainable params: 2,570,960\n","Non-trainable params: 6,812\n","_________________________________________________________________\n","25/25 [==============================] - 2s 17ms/step - loss: 0.3221 - accuracy: 0.8903\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5d273d560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 466ms/step - loss: 0.5053 - accuracy: 0.5926\n","Model evaluation  [0.5052556395530701, 0.5925925970077515]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k9Isl9l0EFqU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPCwX94i_Vc9","executionInfo":{"status":"ok","timestamp":1616335777940,"user_tz":-330,"elapsed":955,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"2a2873d7-18e1-4c2c-c1de-b88a0b1a9b18"},"source":["!wget https://raw.githubusercontent.com/Dinesh-Adhithya-H/Applied-machine-learning/master/Test-Kaggle-Data.csv"],"execution_count":24,"outputs":[{"output_type":"stream","text":["--2021-03-21 14:09:38--  https://raw.githubusercontent.com/Dinesh-Adhithya-H/Applied-machine-learning/master/Test-Kaggle-Data.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1631 (1.6K) [text/plain]\n","Saving to: ‘Test-Kaggle-Data.csv’\n","\n","\rTest-Kaggle-Data.cs   0%[                    ]       0  --.-KB/s               \rTest-Kaggle-Data.cs 100%[===================>]   1.59K  --.-KB/s    in 0s      \n","\n","2021-03-21 14:09:38 (17.4 MB/s) - ‘Test-Kaggle-Data.csv’ saved [1631/1631]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DfSA_lOcCen8","executionInfo":{"status":"ok","timestamp":1616343155280,"user_tz":-330,"elapsed":906,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["test_data=pd.read_csv(\"/content/Test-Kaggle-Data.csv\")"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRJQ0XIqClGe","executionInfo":{"status":"ok","timestamp":1616343155594,"user_tz":-330,"elapsed":924,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["test_data.drop([\"Id\"],inplace=True,axis=1)"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"id":"vaOSiAGAHtlT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKND7ZaODk4J","executionInfo":{"status":"ok","timestamp":1616322227357,"user_tz":-330,"elapsed":2277,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"2e8c711e-e294-45fe-c6ea-95f8623271fb"},"source":["model=create_model()\n","history=model.fit(X,Y,epochs=32)"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Model: \"sequential_46\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_228 (Dense)            (None, 10)                70        \n","_________________________________________________________________\n","dense_229 (Dense)            (None, 12)                132       \n","_________________________________________________________________\n","dropout_136 (Dropout)        (None, 12)                0         \n","_________________________________________________________________\n","dense_230 (Dense)            (None, 18)                234       \n","_________________________________________________________________\n","dropout_137 (Dropout)        (None, 18)                0         \n","_________________________________________________________________\n","dense_231 (Dense)            (None, 18)                342       \n","_________________________________________________________________\n","dropout_138 (Dropout)        (None, 18)                0         \n","_________________________________________________________________\n","batch_normalization_141 (Bat (None, 18)                72        \n","_________________________________________________________________\n","dense_232 (Dense)            (None, 18)                342       \n","_________________________________________________________________\n","dropout_139 (Dropout)        (None, 18)                0         \n","_________________________________________________________________\n","batch_normalization_142 (Bat (None, 18)                72        \n","_________________________________________________________________\n","dense_233 (Dense)            (None, 2)                 38        \n","=================================================================\n","Total params: 1,302\n","Trainable params: 1,230\n","Non-trainable params: 72\n","_________________________________________________________________\n","Epoch 1/32\n","9/9 [==============================] - 1s 2ms/step - loss: 2.3025 - accuracy: 0.7470\n","Epoch 2/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9804\n","Epoch 3/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9907\n","Epoch 4/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9860\n","Epoch 5/32\n","9/9 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9923\n","Epoch 6/32\n","9/9 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9703\n","Epoch 7/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9961\n","Epoch 8/32\n","9/9 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9764\n","Epoch 9/32\n","9/9 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9841\n","Epoch 10/32\n","9/9 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9916\n","Epoch 11/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9932\n","Epoch 12/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9979\n","Epoch 13/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9951\n","Epoch 14/32\n","9/9 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.8584\n","Epoch 15/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.8964\n","Epoch 16/32\n","9/9 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9643\n","Epoch 17/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9618\n","Epoch 18/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9659\n","Epoch 19/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9784\n","Epoch 20/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9679\n","Epoch 21/32\n","9/9 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9020\n","Epoch 22/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.8926\n","Epoch 23/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9303\n","Epoch 24/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9507\n","Epoch 25/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9631\n","Epoch 26/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9130\n","Epoch 27/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9299\n","Epoch 28/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9292\n","Epoch 29/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9223\n","Epoch 30/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9211\n","Epoch 31/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9624\n","Epoch 32/32\n","9/9 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9444\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nr4lOaaMEQuK","executionInfo":{"status":"ok","timestamp":1616321364548,"user_tz":-330,"elapsed":784,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"a5f76903-b468-43e2-bf4e-a3a9fedf2889"},"source":["X.shape"],"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(275, 6)"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8XDU92EEhoV","executionInfo":{"status":"ok","timestamp":1616321365990,"user_tz":-330,"elapsed":1101,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"057615eb-6ef3-4991-d9df-40539c4554ca"},"source":["np.mean(np.abs(model.predict(np.array(X))[:,1]-Y))"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5011790416457437"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3jO1JJQZJjjY","executionInfo":{"status":"ok","timestamp":1616321368195,"user_tz":-330,"elapsed":1197,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"0c8f1cdf-a394-4b21-f96c-6c1b6b805304"},"source":["test_data.shape"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(70, 6)"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"xqPs0yRXTQVK","executionInfo":{"status":"ok","timestamp":1616343160205,"user_tz":-330,"elapsed":1083,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["test_data=m.transform(np.array(test_data))"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fS37gWpTnsA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616321392307,"user_tz":-330,"elapsed":765,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"e305d022-60d9-46c1-c53b-586f29dce164"},"source":["model.predict(test_data)[:,0]"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.27351195, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 1.        , 0.        , 0.        , 0.        ,\n","       0.        , 1.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 1.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"B1CmszbOUapn","executionInfo":{"status":"ok","timestamp":1616336042948,"user_tz":-330,"elapsed":946,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["df=pd.DataFrame()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXFcHBqhVnQ8","executionInfo":{"status":"ok","timestamp":1616336045229,"user_tz":-330,"elapsed":1739,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["df[\"Category\"]=clf.predict(np.array(test_data))+1\n","df[\"Id\"]=np.arange(1,71,1)\n","df=df.set_index([\"Id\"])"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431},"id":"RrQzDb0oWDZx","executionInfo":{"status":"ok","timestamp":1616336046639,"user_tz":-330,"elapsed":635,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"546a42b6-75d0-4555-9929-4850726afc73"},"source":["df"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>70 rows × 1 columns</p>\n","</div>"],"text/plain":["    Category\n","Id          \n","1          1\n","2          2\n","3          1\n","4          1\n","5          1\n","..       ...\n","66         1\n","67         2\n","68         2\n","69         1\n","70         1\n","\n","[70 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"0oPz7gxEWZp0","executionInfo":{"status":"ok","timestamp":1616336049811,"user_tz":-330,"elapsed":773,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}}},"source":["df.to_csv(\"18097.csv\")"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgPO8_YTXI6z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615979176595,"user_tz":-330,"elapsed":960,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"9033ebd0-8f97-48a8-e22e-7201c82385c7"},"source":["model.predict(x_test)[:,1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.9855622, 0.0104083, 0.9855622, 0.9855622, 0.0104083, 0.0104083,\n","       0.9855622, 0.9855622, 0.9855622, 0.9855622, 0.9855622, 0.0104083,\n","       0.9855622, 0.9855622, 0.9855622, 0.9855622, 0.9855622, 0.9855622,\n","       0.9855622, 0.9855622, 0.9855622, 0.9855622, 0.9855622, 0.9855622,\n","       0.0104083, 0.0104083, 0.9855622, 0.0104083, 0.0104083, 0.0104083,\n","       0.0104083, 0.9855622, 0.9855622, 0.0104083, 0.9855622, 0.0104083,\n","       0.0104083, 0.9855622, 0.9855622, 0.0104083, 0.0104083, 0.9855622,\n","       0.9855622, 0.0104083, 0.9855622, 0.0104083, 0.9855622, 0.0104083,\n","       0.0104083, 0.0104083, 0.9855622, 0.0104083, 0.9855622, 0.9855622,\n","       0.0104083, 0.9855622, 0.0104083, 0.9855622, 0.9855622, 0.9855622,\n","       0.9855622, 0.0104083, 0.9855622, 0.0104083, 0.9855622, 0.9855622,\n","       0.0104083, 0.0104083], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":121}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2QsDdC1_xf5H","executionInfo":{"status":"ok","timestamp":1615978655717,"user_tz":-330,"elapsed":743,"user":{"displayName":"H Dinesh Adhithya 18097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTU-cEyJrcQWn_pwwKPs3BOxePx5_1IU2piWHiqA=s64","userId":"10548530627908140815"}},"outputId":"dfe6218f-f0ae-4fbe-8a0b-25e87ad1767d"},"source":["y_test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n","       0, 1, 1, 0, 0])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"hsPagCeuyDgK"},"source":[""],"execution_count":null,"outputs":[]}]}